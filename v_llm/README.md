# BioMistral Clinical Assistant

Assistant mÃ©dical basÃ© sur BioMistral-7B fine-tunÃ© pour l'aide Ã  la prescription d'imagerie cÃ©rÃ©brale selon les guidelines HAS/SFETD 2017.

## ğŸ¯ FonctionnalitÃ©s

- **RAG (Retrieval-Augmented Generation)** : Interroge une base de directives mÃ©dicales
- **Format structurÃ©** : Sorties `Pour prÃ©ciser:` ou `Recommandation:`
- **Fine-tuning spÃ©cialisÃ©** : 200 cas cliniques (cÃ©phalÃ©es, red flags, grossesse, traumatisme)
- **ModÃ¨le quantifiÃ© Q8_0** : Balance qualitÃ©/performance pour dÃ©ploiement Ollama

## ğŸ“ Structure du projet

```
v_llm/
â”œâ”€â”€ src/                    # Code source principal
â”‚   â”œâ”€â”€ main.py            # CLI interactive
â”‚   â”œâ”€â”€ ollama.py          # Interface Ollama + RAG
â”‚   â””â”€â”€ indexage.py        # Indexation ChromaDB
â”‚
â”œâ”€â”€ data/                   # DonnÃ©es et guidelines
â”‚   â”œâ”€â”€ guidelines.json    # Directives mÃ©dicales
â”‚   â”œâ”€â”€ clinical_cases_train.jsonl  # 160 cas d'entraÃ®nement
â”‚   â””â”€â”€ clinical_cases_val.jsonl    # 40 cas de validation
â”‚
â”œâ”€â”€ training/               # Pipeline d'entraÃ®nement
â”‚   â”œâ”€â”€ generate_finetune_dataset.py    # GÃ©nÃ©ration dataset
â”‚   â”œâ”€â”€ finetune_biomistral_unsloth.py  # Fine-tuning (Colab)
â”‚   â”œâ”€â”€ merge_biomistral.py             # Merge LoRA
â”‚   â””â”€â”€ convert-hf-to-gguf.py           # Conversion GGUF
â”‚
â”œâ”€â”€ models/                 # ModÃ¨les finaux
â”‚   â”œâ”€â”€ biomistral_clinical_lora_v2/           # Adapters LoRA
â”‚   â”œâ”€â”€ biomistral_clinical_lora_v2_merged/    # ModÃ¨le HF mergÃ©
â”‚   â””â”€â”€ biomistral_clinical_lora_v2_merged-q8_0.gguf  # GGUF production
â”‚
â”œâ”€â”€ evaluation/             # Ã‰valuation
â”‚   â””â”€â”€ evaluate_model.py  # Script d'Ã©valuation automatique
â”‚
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ CLEANUP_REPORT.md
â”‚   â””â”€â”€ CLEANUP_SUMMARY.md
â”‚
â”œâ”€â”€ gguf-py/               # BibliothÃ¨que GGUF
â”‚
â”œâ”€â”€ Modelfile              # Configuration Ollama
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ run_cli.sh            # ğŸš€ Lancer l'interface CLI
â”œâ”€â”€ run_evaluation.sh     # ğŸ“Š Lancer l'Ã©valuation
â””â”€â”€ .gitignore
```

## ğŸš€ DÃ©marrage rapide

### 1. Installation

```bash
# Installer les dÃ©pendances
pip install -r requirements.txt

# CrÃ©er le modÃ¨le Ollama
ollama create biomistral-clinical -f Modelfile

# VÃ©rifier que le modÃ¨le est disponible
ollama list | grep biomistral
```

### 2. Utilisation

#### Interface CLI interactive
```bash
./run_cli.sh
# ou
python src/main.py
```

**Exemple d'utilisation :**
```
MÃ©decin: Patient 45 ans, cÃ©phalÃ©es

BioMistral: Pour prÃ©ciser: Depuis quand et quel caractÃ¨re ont les cÃ©phalÃ©es 
(brutale / intense / progressive) ? | Y aâ€‘tâ€‘il fiÃ¨vre, vomissements, perte 
de connaissance, convulsions ou dÃ©ficit neurologique focal ? | La patiente 
estâ€‘elle enceinte, aâ€‘tâ€‘elle des antÃ©cÃ©dents majeurs (cancer, immunodÃ©pression) 
ou un traumatisme crÃ¢nien rÃ©cent ?

MÃ©decin: progressive depuis 3 semaines

BioMistral: Recommandation: Pas d'imagerie en premiÃ¨re intention si absence 
de signes d'alerte; traitement symptomatique et suivi ambulatoire. Refaire 
une Ã©valuation si persistance/majoration.
```

#### Ã‰valuation
```bash
# Ã‰valuer sur 5 cas
./run_evaluation.sh --limit 5

# Ã‰valuation complÃ¨te (40 cas)
./run_evaluation.sh
```

#### Test direct
```bash
ollama run biomistral-clinical "Patient 55 ans, cÃ©phalÃ©es brutales depuis 2h"
```

## ğŸ”¬ Workflow d'entraÃ®nement

### 1. GÃ©nÃ©ration du dataset
```bash
cd training
python generate_finetune_dataset.py --n 200
# Produit: ../data/clinical_cases_train.jsonl (160 cas)
#         ../data/clinical_cases_val.jsonl (40 cas)
```

### 2. Fine-tuning (Colab recommandÃ©)
```bash
# Sur Colab avec GPU T4/A100
python finetune_biomistral_unsloth.py \
    --model_name BioMistral/BioMistral-7B \
    --train_file ../data/clinical_cases_train.jsonl \
    --val_file ../data/clinical_cases_val.jsonl \
    --output_dir ../models/biomistral_clinical_lora_v2 \
    --num_train_epochs 3 \
    --batch_size 2
```

### 3. Merge des adapters LoRA
```bash
python merge_biomistral.py
# Produit: ../models/biomistral_clinical_lora_v2_merged/
```

### 4. Conversion GGUF
```bash
python convert-hf-to-gguf.py \
    ../models/biomistral_clinical_lora_v2_merged/ \
    --outfile ../models/biomistral_clinical_lora_v2_merged-q8_0.gguf \
    --outtype q8_0
```

### 5. CrÃ©ation du modÃ¨le Ollama
```bash
cd ..
ollama create biomistral-clinical -f Modelfile
```

## ğŸ“Š MÃ©triques d'Ã©valuation

Le script `evaluate_model.py` calcule :
- **Format compliance** : % de sorties respectant le format attendu
- **PrÃ©cision de classe** : % de recommandations correctes (clarify/urgent/non-urgent/no imaging)
- **Urgence precision/recall** : MÃ©triques spÃ©cifiques aux cas urgents (red flags)

### Exemple de rapport
```
Cas Ã©valuÃ©s : 40
Format conforme : 95.0% (38/40)
PrÃ©cision de classe : 72.5% (29/40)
Urgence â€“ prÃ©cision : 85.7% (TP=6, prÃ©dits=7)
Urgence â€“ rappel : 75.0% (positifs rÃ©els=8)
```

## ğŸ”§ Configuration

### Modelfile (Ollama)
```
FROM ./models/biomistral_clinical_lora_v2_merged-q8_0.gguf

PARAMETER temperature 0.0
PARAMETER top_p 0.9
PARAMETER num_ctx 4096

SYSTEM """Tu es un assistant mÃ©dical expert..."""
```

### Prompt systÃ¨me
Le prompt dans `src/ollama.py` force :
1. VÃ©rification systÃ©matique des signes d'alerte
2. Questions standardisÃ©es si info manquante
3. Format strict `Pour prÃ©ciser:` / `Recommandation:`
4. Justification basÃ©e sur les guidelines RAG

## ğŸ“š Guidelines mÃ©dicales

Le fichier `data/guidelines.json` contient :
- CritÃ¨res d'imagerie urgente (HAS/SFETD 2017)
- Red flags : cÃ©phalÃ©e brutale, dÃ©ficit neuro, fiÃ¨vre, convulsions, perte de connaissance
- Cas spÃ©cifiques : grossesse, immunodÃ©pression, traumatisme, Ã¢ge >50 ans
- Protocoles d'imagerie : IRM vs Scanner, avec/sans injection, dÃ©lai

## ğŸ› ï¸ DÃ©veloppement

### Ajouter des guidelines
```json
{
  "id": "guideline_10",
  "motif": "Nouveau contexte",
  "texte": "Description de la directive...",
  "source": "RÃ©fÃ©rence mÃ©dicale"
}
```

### Modifier le prompt systÃ¨me
Ã‰diter `src/ollama.py`, fonction `rag_biomistral_query()`, variable `prompt`.

### Simplifier la logique CLI
Si le modÃ¨le fine-tunÃ© gÃ¨re bien les clarifications, simplifier `src/main.py` lignes 40-100.

## ğŸ“¦ DÃ©pendances principales

```
transformers>=4.57.0
peft>=0.17.0
unsloth
torch>=2.9.0
chromadb
ollama
gguf-py (local)
```

## âš ï¸ Notes importantes

1. **ModÃ¨le de base** : BioMistral-7B doit Ãªtre tÃ©lÃ©chargÃ© sÃ©parÃ©ment (~14 GB)
2. **Fine-tuning** : NÃ©cessite GPU (Colab recommandÃ©, T4 minimum)
3. **Ollama** : Le modÃ¨le `biomistral-clinical:latest` doit Ãªtre crÃ©Ã© localement
4. **ChromaDB** : Base RAG reconstruite Ã  chaque lancement (pas de persistance)

## ğŸ” Debugging

### Le modÃ¨le ne respecte pas le format
- VÃ©rifier la tempÃ©rature (doit Ãªtre 0.0 pour dÃ©terminisme)
- Relancer avec `./run_evaluation.sh --limit 1` pour tester

### Erreur "Model not found"
```bash
ollama list
# Si absent :
ollama create biomistral-clinical -f Modelfile
```

### Erreur de chemin
Tous les scripts utilisent des chemins relatifs depuis leur position.  
Toujours lancer depuis la racine du projet ou utiliser les wrappers `run_*.sh`.

## ğŸ“ˆ Performance

| MÃ©trique | Valeur |
|----------|--------|
| Taille modÃ¨le (Q8_0) | ~7.5 GB |
| Temps d'infÃ©rence | ~2-3s par requÃªte |
| Format compliance | >95% |
| PrÃ©cision clinique | ~70-75% |

## ğŸ“ TODO

- [ ] AmÃ©liorer la dÃ©tection des nÃ©gations ("sans fiÃ¨vre" mal interprÃ©tÃ©)
- [ ] Enrichir les guidelines avec plus de cas edge
- [ ] Ajouter support multilingue (anglais mÃ©dical)
- [ ] Optimiser la logique de clarification dans `main.py`

## ğŸ“„ Licence

ModÃ¨le de base : BioMistral-7B (Apache 2.0)  
Code : Ã€ dÃ©finir

## ğŸ¤ Contribution

1. Ajouter des cas dans `training/generate_finetune_dataset.py`
2. Fine-tuner avec le dataset Ã©tendu
3. Ã‰valuer avec `./run_evaluation.sh`
4. Documenter les changements

---

**DerniÃ¨re mise Ã  jour** : 20 octobre 2025  
**Version** : 2.0 (structure rÃ©organisÃ©e)
